version: '3.8'

services:
  # ML Service - text-to-SQL модель
  ml-service:
    build:
      context: ./ml
      dockerfile: Dockerfile
    container_name: agentic-ml-service
    ports:
      - "8001:8001"
    volumes:
      - ./ml:/app
      - ml-models:/app/models
    environment:
      - MODEL_NAME=NumbersStation/nsql-llama-2-7B
      - MODEL_CACHE_DIR=/app/models
      - LOG_LEVEL=INFO
    healthcheck:
      test: ["CMD", "python", "-c", "import requests; requests.get('http://localhost:8001/health')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - agentic-network
    restart: unless-stopped

  # Backend FastAPI
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: agentic-backend
    ports:
      - "8000:8000"
    volumes:
      - ./backend/app:/app/app
      - ./data:/app/data
    environment:
      - DATABASE_PATH=/app/data
      - ML_SERVICE_URL=http://ml-service:8001
      - LOG_LEVEL=INFO
      - CORS_ORIGINS=http://localhost:3000,http://localhost
    depends_on:
      ml-service:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python", "-c", "import requests; requests.get('http://localhost:8000/health')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 5s
    networks:
      - agentic-network
    restart: unless-stopped

  # Frontend Nginx
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: agentic-frontend
    ports:
      - "3000:80"
    depends_on:
      backend:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost/"]
      interval: 30s
      timeout: 3s
      retries: 3
      start_period: 5s
    networks:
      - agentic-network
    restart: unless-stopped

networks:
  agentic-network:
    driver: bridge

volumes:
  ml-models:
    driver: local